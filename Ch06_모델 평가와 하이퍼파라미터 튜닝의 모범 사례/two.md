# 머신러닝 모델 성능 평가 (홀드아웃 및 k-겹 교차 검증)

모델이 너무 간단하면 과소적합(높은 편향)이 문제가 되기도하고, 모델이 너무 복잡하면 훈련 데이터에 과대적합(높은 분산)이 일어나 문제가 되곤 합니다.  
이런 현상을 피해 적절한 편향-분산 trade-off를 찾기 위해서는 모델을 잘 평가해야 하는데, 대표적인 교차 검증 기법인 `홀드아웃 교차 검증(holdout cross-validation)`과 `k-겹 교차 검증(k-fold cross-validation)`을 이용하여 신뢰 할만한 추정을 찾습니다.  
이는 모델의 일반화 성능, 즉 처음 본 데이터에 모델이 얼마나 잘 동작하는지 추정하도록 도와줍니다.

### 홀드아웃 교차 검증(holdout cross-validation)

![holdout cross-validation](http://cfile1.uf.tistory.com/image/9955CF485E24EFD222FB59)

데이터셋을 모델 훈련에 사용할 `훈련 세트`와 일반화 성능을 추정하는데 사용할 `테스트 세트`로 나눕니다.  
그리고 예측 성능을 높이기 위해 하이퍼파라미터를 튜닝하고 비교해야 하는데,  
이때 모델 선택에 같은 테스트 세트를 반복해서 재사용하면 이는 훈련 세트의 일부가 되는 셈이고 모델이 과적합되는데 원인이 됩니다.  
그러므로 데이터 셋을 `훈련 세트`, `검증 세트`, `테스트 세트`로 나누는 것이 적합합니다.  
검증 세트를 이용하여 다른 하이퍼파라미터 값에서 모델을 훈련하는 것을 계속 반복하고 성능을 평가한 뒤, 만족할만한 성능이 나온 하이퍼파라미터를 이용하여 테스트 세트에서 모델의 일반화 성능을 추정합니다.

![holdout cross-validation](http://cfile27.uf.tistory.com/image/994042405E24E8081C326A)

### k-겹 교차 검증(k-fold cross-validation)

![k-fold cross-validation](http://cfile9.uf.tistory.com/image/99D6E7505E24EFF2213FB3)

k-겹 교차 검증은 홀드아웃에 비해 훈련 세트의 분할에 덜 민감한 성능 추정을 얻을 수 있습니다.  
중복을 허락하지 않고 훈련 데이터셋을 k개의 폴드로 랜덤하게 나눈 뒤, k-1개의 폴드로 모델을 훈련하고 나머지 하나의 폴드로 성능을 평가합니다.  
이 과정을 k번 반복하여 k개의 모델과 성능 추정을 얻습니다.  
만족할만한 성능이 나온 하이퍼파라미터를 찾은 후에는 전체 훈련 세트를 사용하여 모델을 다시 훈련하고 독립적인 테스트 세트를 이용하여 최종 성능 추정을 합니다.

> 훈련 세트가 작다면 폴드 갯수를 늘리는것이 좋다.  
> k 값이 증가하면 훈련 데이터가 더 여러번 반복해서 사용되고, 모델 성능을 평균하여 일반화 성능을 추정할 때 더 낮은 편향을 만든다.

### 계층적 k-겹 교차 검증(stratified k-fold cross-validation)

데이터가 한쪽으로 편향되어 있을 경우 k-겹 교차검증을 사용했을때 성능 평가가 잘 되지 않을 수 있다.  
그럴때 계층적 k-겹 교차 검증을 사용한다.  
계층적 k-겹 교차 검증은 각 폴드에서 클래스 비율이 전체 훈련 세트에 있는 클래스 비율을 대표하도록 유지합니다.

> 일반적으로 회귀에는 k-겹 교차검증을 사용하고 분류에는 StratifiedKFold를 사용한다.